{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPtzIN0Gq6gd"
   },
   "source": [
    "# CNN Exercise 2: Image Classification with CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wAf6U4cq6gj"
   },
   "source": [
    "We will use the CIFAR10 dataset, which consists of 60000 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The classes are: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. In this exercise we will only use the dog and cat classes and we will train a CNN to distinguish between the two.\n",
    "\n",
    "In the following cell we load the dataset again from ```torchvision.datasets```. There is a bunch of code that is not relevant for this exercise, but you can have a look at it if you are interested. The important part is that we load training and test data, only select the dog and cat classes, and do some augmentation and normalizing of the data.\n",
    "\n",
    "Thanks to [this Gist](https://gist.github.com/Miladiouss/6ba0876f0e2b65d0178be7274f61ad2f) for the code to load the CIFAR10 dataset.\n",
    "\n",
    "Created by Cedric Ewen in 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7iOMUrJq6gm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBJufeElq6go"
   },
   "outputs": [],
   "source": [
    "# device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g5uYCD7Dq6gp"
   },
   "outputs": [],
   "source": [
    "# transformations\n",
    "RC = transforms.RandomCrop(32, padding=4)\n",
    "RHF = transforms.RandomHorizontalFlip()\n",
    "NRM = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "TT = transforms.ToTensor()\n",
    "\n",
    "# transforms object for trainset with augmentation\n",
    "transform_with_aug = transforms.Compose([TT, RC, RHF, NRM])\n",
    "# transforms object for testset w/o augmentation\n",
    "transform_no_aug = transforms.Compose([TT, NRM])\n",
    "\n",
    "# downloading/louding CIFAR10 data\n",
    "trainset = CIFAR10(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_with_aug)\n",
    "testset = CIFAR10(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_no_aug)\n",
    "classDict = {'plane': 0, 'car': 1, 'bird': 2, 'cat': 3, 'deer': 4,\n",
    "             'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog',\n",
    "           'horse', 'ship', 'truck']\n",
    "\n",
    "# separating trainset/testset data/label\n",
    "x_train = trainset.data\n",
    "x_test = testset.data\n",
    "y_train = np.array(trainset.targets)\n",
    "y_test = np.array(testset.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtKiTPTqq6gr"
   },
   "source": [
    "We now choose the classes we want to use for the classification. We start with cats and dogs and will later add more classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8P25nj9tq6gs"
   },
   "outputs": [],
   "source": [
    "# This code block will remove all data samples that do not belong to\n",
    "# class 'cat' or to class 'dog'.\n",
    "classes = ['cat', 'dog']\n",
    "\n",
    "# all classes of CIFAR-10\n",
    "#classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# initialize masks and map according to chosen classes\n",
    "mask_train = np.zeros(len(y_train), dtype=bool)\n",
    "mask_test = np.zeros(len(y_test), dtype=bool)\n",
    "lable_map = {}\n",
    "for i, class_name in enumerate(classes):\n",
    "    mask_train = mask_train | (y_train == classDict[class_name])\n",
    "    mask_test = mask_test | (y_test == classDict[class_name])\n",
    "    lable_map[classDict[class_name]] = i\n",
    "\n",
    "# select data\n",
    "trainset.data = x_train[mask_train]\n",
    "testset.data = x_test[mask_test]\n",
    "trainset.targets = y_train[mask_train].tolist()\n",
    "testset.targets = y_test[mask_test].tolist()\n",
    "\n",
    "# make class labels continuous again\n",
    "trainset.targets = [lable_map[e] for e in trainset.targets]\n",
    "testset.targets = [lable_map[e] for e in testset.targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSf-uh69q6gs",
    "outputId": "88ac3e2e-9fbb-42b7-f851-b26f98dd4e4b"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# create dataset loaders from trainset and testset\n",
    "kwargs = {'num_workers': 4, 'pin_memory': False,\n",
    "          'batch_size': batch_size}\n",
    "trainloader = DataLoader(\n",
    "    trainset, shuffle=True, **kwargs)\n",
    "testloader = DataLoader(\n",
    "    testset, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lERWPcSFq6gt"
   },
   "source": [
    "We now have a training and test set of the selected classes that are one-hot-encoded. Let's look at some of the images.\n",
    "- What's the size of the images?\n",
    "- How many images do we have in training and test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "6NX5EYYnq6gv",
    "outputId": "4d254e20-2547-4ee2-ba75-aeb7b86211e8"
   },
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "images_to_plot = 8\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:images_to_plot]))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(images_to_plot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qVfM4ccHq6gw"
   },
   "outputs": [],
   "source": [
    "# TODO: print image shape and dataset length\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sz8thAasq6gw"
   },
   "source": [
    "# Define the Network\n",
    "This is the only area you will need to change.  Look at the picture of LeNet here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxPOwe9fwLe9"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #TODO: define the layers\n",
    "\n",
    "        # You can implement the network from exercise 1.\n",
    "        # Try not to do copy-and-paste.\n",
    "        # You will have to change some numbers because the image size is different and we now have RGB instead of greyscale.\n",
    "        # We also use only 2 classes (cats and dogs) now instead of 10.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #TODO: run layer\n",
    "\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HS6eiVDcq6gx"
   },
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MagSwBEVq6gy"
   },
   "outputs": [],
   "source": [
    "summary(model, (3, 32, 32), batch_size=batch_size, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxoN7JUHq6gy"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MW5myztyq6gy"
   },
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUsfspjlq6gz"
   },
   "outputs": [],
   "source": [
    "# move model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O06lonU5q6gz"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJtJ0secq6g0"
   },
   "source": [
    "The training loop is the same as in the previous exercise. The only difference is that we have added a validation loop, where we evaluate the model on the validation set (in our case the test data). We additionally save the loss and accuracy for both the training and validation set in a list, so that we can plot them later. The accuracy is the fraction of correctly classified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGF41xHAq6g0"
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, model, trainloader, testloader):\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracy = []\n",
    "\n",
    "    val_losses = []\n",
    "    val_accuracy = []\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        # In this loop 2 important lines are missing\n",
    "        # Do you notice what's missing?\n",
    "        # Hint: Compare to train() in exercise 1\n",
    "        for i, (images, labels) in enumerate(trainloader, 0):\n",
    "\n",
    "            # move data to GPU\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # run model\n",
    "            output = model(images)\n",
    "\n",
    "\n",
    "            # clear gradients for this training step\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # backpropagation, compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "\n",
    "            # save metrics for ploting\n",
    "            train_loss += loss.item()\n",
    "            train_acc += (output.argmax(dim=1) == labels).float().mean().item()\n",
    "\n",
    "        train_loss = train_loss / len(trainloader)\n",
    "        train_acc = train_acc / len(trainloader)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracy.append(train_acc)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():  #switch off autograd\n",
    "            val_loss = 0.0\n",
    "            val_acc = 0.0\n",
    "            for i, (images, labels) in enumerate(testloader, 0):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                pred = model(images)\n",
    "                v_loss = loss_func(pred, labels)\n",
    "                val_loss += v_loss.item()\n",
    "                val_acc += (pred.argmax(dim=1) == labels).float().mean().item()\n",
    "\n",
    "            val_loss = val_loss / len(testloader)\n",
    "            val_acc = val_acc / len(testloader)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracy.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs} | loss: {train_loss} - acc: {train_acc} | val_loss: {val_loss} - val_acc: {val_acc}\")\n",
    "\n",
    "    print(f\"Finished training after {num_epochs} epochs\")\n",
    "    print(f\"Best validation accuracy: {max(val_accuracy)}\")\n",
    "    return train_losses, val_losses, train_accuracy, val_accuracy\n",
    "\n",
    "num_epochs = 50\n",
    "train_losses, val_losses, train_accuracy, val_accuracy = train(num_epochs, model, trainloader, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEzGgsrtq6g0"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "pmIPbxESq6g0",
    "outputId": "7f102e0c-0f79-4cea-9436-991e2cd048a9"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.array(train_losses), label='Training loss')\n",
    "plt.plot(np.array(val_losses), label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "DnPZliSCq6g1",
    "outputId": "c259fe2c-a75c-4025-deed-1bc9dc521b81"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.array(train_accuracy), label='Training Accuracy')\n",
    "plt.plot(np.array(val_accuracy), label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5n4GtSKIq6g1"
   },
   "source": [
    "In the following, we will evaluate the last epoch on the test dataset and calculate the accuracy, look at some outputs and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLk9UZXpq6g2",
    "outputId": "04f2521c-73b2-4761-e19c-63332a6c845d"
   },
   "outputs": [],
   "source": [
    "# predicting labels for test data and calculating accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "test_images = []\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images.to(device))\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_preds.append(predicted.cpu())\n",
    "        test_labels.append(labels.cpu())\n",
    "        test_images.append(images.cpu())\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.cpu() == labels).sum().item()\n",
    "    test_preds = torch.cat(test_preds).numpy()\n",
    "    test_labels = torch.cat(test_labels).numpy()\n",
    "    test_images = torch.cat(test_images)\n",
    "\n",
    "print(f'Accuracy of the network on the {total} test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nqadhnHEq6g2"
   },
   "outputs": [],
   "source": [
    "images_to_plot = 8\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(test_images[:images_to_plot]))\n",
    "# print labels\n",
    "print('Truth:     ', ' '.join(f'{classes[test_labels[j]]:5s}' for j in range(images_to_plot)))\n",
    "print('Predicted: ', ' '.join(f'{classes[test_preds[j]]:5s}' for j in range(images_to_plot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 619
    },
    "id": "wQdh82Ehq6g2",
    "outputId": "0444995c-9198-4a6e-d47c-9ac76cb4f10c"
   },
   "outputs": [],
   "source": [
    "# Create confusion matrix and normalizes it over true labels\n",
    "confusion = confusion_matrix(test_labels, test_preds, normalize='true')\n",
    "\n",
    "# Create a plot of the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "ConfusionMatrixDisplay(confusion, display_labels=classes).plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gqwcvz8xq6g2"
   },
   "source": [
    "# Task\n",
    "\n",
    "**Create a CNN that achieves a validation accuracy of at least 70%**\n",
    "\n",
    "- Feel free to experiment on the network structure yourself. Use a combination of convolutional and pooling layers, similar to the first exercise.\n",
    "- If your train and validation metrics diverge, you should consider including [Dropout layers](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html).\n",
    "\n",
    "# Bonus tasks\n",
    "\n",
    "- A network with many parameters may perform better but a small network is trained faster and requires less computing resources. Can you reach the 70% validation accuracy in less than 20 epochs?\n",
    "- The dataset does not only contain Cat and Dog pictures but 10 classes in total. You could rebuild the model as a multi-classifier. To achieve this, you would need to:\n",
    "    - Include additional classes in your input. Do this by commenting out the one line of code in the data loading section.\n",
    "    - What else do you need to change to make the model a multi-classifier?\n",
    "    - Try to achieve the best validation accuracy you can. Which other parameters besides the architecture can you change to affect the performance?\n",
    "- Implement a ResNet and apply it to the dataset. For example, you can add another class inheriting from `nn.Module` that implements a single reset block, including two convolutions, activation function and the skip connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
